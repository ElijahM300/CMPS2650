Keynote Address
Cory Doctorow
SCALE 14x

So, the long history of Free and Open Software has been defined in many ways as the fight between proprietary and open methodologies.  You know, infamously Bug Zero for Ubuntu, you know, people still use Microsoft products.  And back in the late 90s, back when it was LUGfests, that was the thing that everyone was concerned about, whether there was Free of proprietary software being used in our applications. And there's good reason to worry about whether the methodology is Free or open, because things are more robust when they're open, for reasons that are connected to practices and other disciplines, right?
Before we had science we had a thing that looked a lot like science, it was called alchemy.  Alchemy and science have a lot of similarities in their methodologies.  An alchemist observes a phenomenon in the natural world, and hypothesizes a causal relationship, "I think this phenomenon is caused by that," and formulates an experiment to see if that causal relationship is true, and then runs the experiment.  And so far it's just like science, the big difference is that alchemist never tell other alchemists what they think they just discovered.
And as a result, they are prone to the worst of human failings, the most universal of human failings, our endless capacity for self deception. Right, and so you run the experiment, you think you know what emerged from it, and by an amazing coincidence it's what you expected would emerge from it, and you were really bright to have come up with that hypothesis, and that way you discover in the hardest way possible that you shouldn't drink mercury.  Right.  And that's why alchemy stalled out, right?  That's why we had 500 years of alchemy, a period we call "The Dark Ages," in which science effectively failed to produce any dividends.
And then alchemists did something that really did convert something base into something precious, they began to publish their results, and subject them to adversarial peer review. Which is when your friends gently point out the mistakes you've made, and your enemies tell you what an idiot you were to have made them.  And by doing so they subjected their findings to rigor, and that rigor produced advancements, and those advancements produced the Enlightenment.
And that today is the way is the way we do everything of significance. Right?  You never never heard of a proprietary conference center, right?  If you hired a firm of engineers to built this conference center and they said, "All right, we're going to put these reinforced steel joists across this big open space to make sure the roof doesn't fall in and kill everyone one day, but we're not going to tell you the math we used to calculate whether or not the load stresses will be adequately accounted for in our reinforced steel joists,"  you shouldn't buy a conference center from those engineers. Right?  We don't have proprietary math for rocketships or even drones, right, even military secrecy involves open math, open methodologies, because the robustness, the vigor comes from being able to understand what's going on.
And a building today is just a computer that we put our bodies into.  Right, if you live in a modern skyscraper, it's got a seismic damper which is a computer connected to a huge mass and that mass is shifted by the computer in response to load stresses from seismic force, from wind shear, and if that computer behaves correctly, then the amount of wobble and rock from that building that is subjected to those forces, will be correctly accounted for, and if that computer were very badly malfunctioning that building would fall over, right?  Bankers work in case-mods and living inside a computer, it really matters whether or not your building is open or proprietary, because it really matters whether you can trust those maths.
And it's not just our computers, not just our buildings. Our cars are computers that we keep our bodies in too.  You know, you get in a car and it drives you at a hundred miles an hour, and you pray that the steering and the brakes and all the other elements that are being run through software are adequately secured.
And we not only keep our bodies inside of computers, we have recently put computers inside of our bodies. If you are someone who has a pacemaker, that pacemaker has a computers in it, and that computer is used not just to calculate how to keep the rhythm of your heart, but to receive telemetry from its performance and your hearts performance and to feed that telemetry back to your doctor, so she can fine-tune your care.  The Internet of Things has metastasized computers into every corner of our life. We now have computers up our asses. Right?
And like I say, historically the fight over whether our computers are good or bad has been a fight over whether they are open or proprietary, Free or proprietary.  But there's a different kind... and we fought proprietary over the last couple of decades with what Larry Lessig calls the four forces... Lawrence Lessig says there are four forces that act on our society, code, law, norms, markets, and, um, code, law, norms, markets... code, law, norms, markets... and... code, law, norms, markets, I'm sorry, I can't count to four this morning.  Code, law, norms, markets!
So, you know, on the one hand, markets, right?  What's the best way to get a web server on-line?  It's Apache.  Right?  It's not IIS.  And so, by making the best commercial offer... or one of Apache's successors, these days obviously, Apache's not the only option anymore... but the way that we got rid of IIS was with Apache, we just made it commercially more attractive to install Free code, open code.
And so we used markets to solve the open and proprietary problem but we also used code, so every now and again we would find something that was already established that was proprietary that we couldn't interface with without some kind of work and we would write code that would interface with it.  So we took SMB and we wrote SAMBA and so you you didn't have to choose whether or not you were going to rip out all of your networking infrastructure and replace it with new networking infrastructure, you could have Free and proprietary living beside each other and you could gradually infiltrate the proprietary with Free, by having good, Free, open code.
We also had norms, right?  Any one of you who has a penguin badge, who's ever had an argument whether Free or proprietary is the right way to go, you were engaged in that normative fight, whether it was moral or ethical to be Free or closed.  We have lots of people who contributed to Free and Open Source Software and made it better, because of their normative views.
And then finally we have laws, right?  There are cities and states and countries that have, to a greater or lesser extent, mandated that source code be available for inspection, or even licensed under a  Free or open license before it could be used in public areas, public applications.

And so code, laws, norms and markets, came together to increase the spread of Free and open source software over the years.  But there's a more profound kind of proprietary that is on our horizon, a kind of proprietary that goes beyond whether or not its license is open or Free, and that's what I really want to talk to you about today.  Because the dangers of proprietary are things that I think are real, and we can fight back with these four tools, code, law, norms and markets, but this kind of hyper-proprietary code is something that's much harder to fight against and much deadlier, and that's code that has DRM in it.
So, in 1998, the American Congress passed the Digital Millennium Copyright Act, this is the DMCA, this is the law that you are all familiar with because it's the author of all your favorite YouTube videos?  "This Video Has Been Removed Under a Claim... Because of a Claim Under the DMCA."  The part of the DMCA that regulates Digital Rights Management, or what Richard Stallman calls Digital Restrictions Management, is Section 1201, and Section 1201 makes it  a crime to break digital rights management, to do anything to weaken a digital lock, to give people information that they could use to break digital locks.
And its importance has only increased since 1998.  So in 1998 when the DMCA was enacted it was a US law.  But since then the US trade representative has been kind of a "Patient Zero" in an epidemic of terrible computer law and has insisted that all of America's trading partners adopt laws that are much like DMCA 1201.  In Europe they enacted the European Union Copyright Directive in 2001, which bound all of the European states to enacting their own version of the DMCA.  In Australia it came in through the US-Australia Free Trade Agreement, in New Zealand it was part of Bill 92A.
Bill 92A has a really dire history, if you want to know just how ugly the sausage making is, look up Bill 92A, because it was originally passed after being rammed through Parliament, people marched in the streets against it.  It was this very expansive copyright bill, it included so-called three strikes provision where if you are accused of three acts of piracy, your Internet service provider would have to remove you from the Internet for a year.  And people marched in the streets against it, and Parliament actually struck down the bill -- and then the Christchurch earthquake hit, which was the worst natural disaster in living memory in New Zealand and Parliament had an emergency session to clear a bill to give aid to the people who were under the rubble in Christchurch, and a lobbyist for the entertainment industry  got someone from Parliament to block the bill's passage until they re-introduced Bill 92A's provisions as a rider, right, so no one gets dug out of the rubble until we get the DMCA.
So it happened in New Zealand.  In Canada, where I'm from,  we got our version, this Bill C11, which is incredibly embarrassing, not because we came late to the party, but because making dumb mistakes about the Internet in 1998 is barely forgivable as a lack of foresight, but if you're still making dumb mistakes about the Internet in 2011, then you're just not paying attention.  Right?  That's just felony stupid, and disqualifies you from having office, as far as I'm concerned.
So, this is spread around the world, it's now law in almost every territory where you can buy or use a computer, but it's also spread through our devices.  So, in 1998, the devices that were covered by the DMCA were pretty limited in scope.  You had things like set-top cable and satellite receivers, DVD players, a few other devices that were emerging into the market, those things that Sony tried to push as successors to the Walkman, that spectacularly failed to get people to buy, when they were insisting that MP3 would never catch on, right?  That was what the DMCA applied to.
And companies tried to apply it to other devices.  A company called Lexmark, now a division of IBM, it was, it became a division of IBM, now I think it's independent again, they make printers, as I'm sure you know, laser printers, they put a bit of DRM in their toner cartridges, and the printer could check to see if you've refilled the toner cartridge because the DRM would flip a bit once the cartridge ran out and you'd have to break the DRM to unflip that bit, and if you flipped the bit it would refuse to run the printer.  And a company called Data Controls made their own version of the chip that would break the DRM and allow you to unlock your printer cartridge and refill it.  There was another company called Skylink that made some really insecure garage door openers that were so insecure that anyone could make an opener for them and they charged a lot of money for the little button, and so another company went into business cracking their DRM and making buttons that would let you open your completely inadequate garage door opener, if you wanted to, for less money, which was a bit of a Malthusian, you know, a bit of a crappy bargain.  Nevertheless, it's one that consumers should be free to make.  And in both cases they sued these competitors making these devices.  And in both cases the federal circuit said, "Actually the DMCA doesn't cover printer cartridges or garage door openers because the DMCA  only covers breaking locks that protect copyrighted work, and the only copyrighted work in your toner cartridge is the DRM. So the DRM is protecting the DRM.  That's too circular, that's not what it's there for."
But a funny thing happened  on the way to the IoT [Internet of Things], right?  If you have... we got a light bulb for Christmas, it has an app, it doesn't work of course, but we got a light bulb for Christmas that has an app.  And that light bulb has a wifi access point, a TCP/IP stack and a Linux kernel, right?  That light bulb has a ton of copyrighted work in it.  No one is going to argue that light bulb doesn't have a copyrighted work in it.  When you put this thermometer in your ass, you have a copyrighted work up your ass. <points to screen>
What that means is that DRM now has the force of law when it restricts access to systems that are not computers in the kind of laptop and phone sense but are computers in the rectal thermometer, car and seismic damper sense.  And this means that the law now applies to virtually everything you use and soon, to effectively everything you use.
Now, the reason companies put this in doesn't have anything to do with piracy.  DRM has never really been any good at fighting piracy for foundational cryptographic reasons.  Normally in crypto you have Alice and Bob and Carol.  Alice and Bob have a secret. They don't want Carol to know it. They assume that Carol can intercept the scrambled message because they use public networks like the Internet or like satellite or like radios. They assume that Carol knows what algorithm they used to scramble the message, because you use public ciphers for the same reasons that scientists use public science--if you're making up your own crypto you're probably getting it wrong.  This is like lesson one in that Corsera Stanford course on crypto, don't roll your own crypto.
Don't roll your own crypto, right?  If it turned out that as a result of the Snowden leaks jihadis made good on their threat to make their own, like Hilal crypto, it would be the greatest day the NSA ever had.  Right?  Because the would pwn that crypto in a matter of hours.
So Alice and Bob use publicly understood crypto.  And they send a message over a public framework that Carol can intercept then.  But Alice and Bob still have a secret.  The way Alice and Bob still have a secret is they don't give Carol the key.   And because crypto works, if you don't have the key, you can scramble a message using trivial computers, the supercomputer in your pocket, you can scramble a message so thoroughly,  that if all the hydrogen atoms in the universe would turn into computers and they did nothing until the end of the universe but try to brute force the key, we would run out of universe before we ran out of possible keys. Right, and so Alice and Bob know that their message is secure, because Carol never gets the key.
But in DRM, there is no Carol, right?  There's just Alice and Bob.  Like Bob is Netflix and Alice is you.  And Bob wants to make sure you don't record your Netflix videos and save them to watch later.  So Bob gives you a plug-in for your browser to decrypt the Netflix stream and that plug-in doesn't have a "Save" button.  And Bob assumes that will never figure out where in that plug-in he hid the key, right? And if you want to become Alice, and figure out where in this property that's now on your premises he hid the key, all you need to do is buy a Netflix subscription.  So any adversary in the world can become Alice for like, ten bucks a month.  And that includes bored grad students with a weekend off and their own tunneling electron microscope, at a lab, right?  So when Bob hides keys in his adversary's equipment, Bob loses.  All the time.
But companies still use DRM, and not in order to increase sales.  No one has ever bought something because it has DRM, right?  You never bought a Netflix subscription because, you're like, you know, "What I want is to watch all the movies, but I want to make sure I can't save them."  Right?  If there were two Netflixes, one of which let you save, and one of which didn't, and the prices were equal, all things being equal you would expect some customers to move from one to the other.  Right, so no one bought it, no one looked on the box and said, "Now with DRM" and said, "That's the one I'm buying."  So, people are either indifferent to the DRM or they're holding their nose and buying it because of DRM or they're just refusing to buy because of DRM.  No one has ever, no incremental new sales emerge because of DRM.
But what you get when you put DRM on a device, is you get the right to decide what kind of otherwise legal technology can plug in to that device.  What kind of features can be added to that device.  Because, even if it's legal to record videos that are coming into your home, and it is, right?  From 1976 to 1984, courts around America heard the case of whether or not recording videos was legal.  In 1984, the Supreme Court legalized VCRs, recording a VCR from your TV to a tape or other media for watching later is legal.  Right?  So whether or not it's legal to watch a Netflix video later because you saved it to your hard drive, is beside the point if the only way you can do that is breaking the DRM.
And you can probably figure out how to record your Netflix video and watch them later-- you have heard of VLC, right?  You have heard of HandBrake.  You know that there are streamrippers and you know how to use them.  But you've never seen an ad on the side of a box for VLC.  No one has ever raised capital for a device to do this and hired some marketing people and set up a booth in a trade show to market this.  There's no one at CES [Consumer Electronic Show] who will give you a product that will let you do this.  Actually there was one company at CES that breaks HDCP to down-sample it for older devices to... it goes from HDCP4 to HDCP2, they're now being sued. Right?  So you can't raise capital for this, you can't make a product for this, and as a result, while a few super-nerds will use it, like "civilians" aren't in possession of these things.  So it's an enormously powerful anti-competitive tool.  It has nothing to do with anti-piracy, and everything to do with anti-competition.
And the way that you can create profit by suppressing competition, really breaks down into three categories.  The first is that you can restrict features.  So think about DVDs and CDs.  DVDs and CDs are functionally equivalent these days--we make them in the same presses, we read them with the same lasers and the same optical drive, but they have a really huge difference.  Which is that DVDs have DRM, DRM that's been broken since a Norwegian teenager spent an afternoon looking at it hard in the mid 1990s.  But DRM that nevertheless still has the force of law. And as a result there are no DVD ripping products.  So if you have a CD and you put it the optical drive that came with your computer, the software that came with your computers automatically launches and says that "I see that you are using media from the last century.  Would you like to rip it, mix it and burn it so that you can use it in this century too?"  Right?  Done in one.
If you put a DVD into your computer, it says "Would you like to watch this?" Watching a DVD is the only feature a DVD had in 1996, watching a DVD is still the only feature that DVD has in 2016. Twenty years, and not one feature added to a technology.  We are back in the dark ages when you add this. When you add DRM to a technology.  And what that gets firms, is new sales, because no one ever bought media because it has DRM on it.  But if you want to listen to a song on your phone, you put the CD in your computer and it moves it to your phone. If you want to watch a movie you own on a DVD on your phone, you buy it again, from the Apple Store, the Amazon Store, one of the other many stores, and so that generates new sales.  By taking value that is under law, yours, and transferring it back to the manufacturer and the industry.
The next way that you can control devices, that you can raise profits by controlling devices, is with parts.  So all of the major auto manufacturers these days have started to put DRM on the CANbus, this is the bus that connects all of the electronics in a car.  Cars are computers you put your body into.  And that DRM is again not hard to break, the people in the tuner community routinely break it, they can change the characteristics of their engines, but it's illegal to break.  And so, if you're a mechanic and you want to run a business that, you know, has an address where you can get sued at, and you want to fix cars, the only way you can get diagnostic material out of an engine is to go to the manufacturer and get their manufacturer supplied diagnostic tool, that has the keys to read the information coming off the engine.  And as a condition of buying that you have to sign a covenant that says, "I'm only buying parts from GM."  Right, so GM can charge arbitrary sums for those parts, and no one can compete with them because a mechanic that uses third party parts that the get off Alibaba and a manual they get from iFixIt can't read the data from the engine to figure out which parts they need to use to fix the engine, register the new parts on the network, and so on.  And that's the second way they make money.
And then the third way to make money with being able to control features, being able to control the software and interoperability is by being able to make promises. So, if you're making a phone, the iPhone, and you're counting on carriers to account for the bulk of your sales, so you sell to the carriers, the carriers give the phone away to their customers with a long contract that pays for it over and over again, you need to be able to make promises to those carriers to maximize your sales to them. So the carriers want to make sure that if you're tethering a device to another device, if you're sharing a network connection from a mobile network to a non-mobile device, that they can detect that, so that if they want to they can charge extra money for it, so they can sell you a tethering plan that's different from a non-tethering plan.  And so, when you add an app-store ecosystem that's locked to the device, where it's a felony to create a new app and install it on the device without permission from the manufacturer, you can say to the phone company, "If you sell iPhones to your customers, if you give iPhones to your customers we can promise you that there will never be an app that does undetectable tethering."  And then the manu-, then the intermediate customer get this.
And it's not just Apple, you know, if you have a Nest thermostat, the primary market for Nest thermostats isn't users who put them in their houses, it's power companies who buy them to put them in users' houses, and they want to be able to turn down on your thermostat by one degree, or turn it up by one degree to change the load across the whole grid, which is a good idea, it's how we're going to keep from using more coal plants, and the way that they make that promise stick is by saying, "We can install software in this thermostat that the user can't override, and we will promise you that the user will never get a package that lets them reverse that."
So that's bad, right, it ends up costing you and me and everyone we love more money and keeps us from having features we desire in our devices.  But that's not the reason that I hate and fear DRM.  That's not the reason I've gone back to the Electronic Frontier Foundation after a ten year hiatus, to work on a project to kill all the DRM in the world.  It's because in order to protect digital locks, you have to ban the disclosure of vulnerabilities in digital locks.  Because if I know about a mistake that the programmer made, I can use that mistake to leverage a jailbreak attack on the device, to figure out how to flash my own firmware to it that adds the feature, that lets me use the third party parts, that lets me extract more value from something I own and use it in another market.
Companies aren't adding DRM because they're hostile to security, but they're using DRM because they are indifferent to it.  Security is a process and not a product.  The only way to know if your security works, our only experimental methodology to determine if it works is to expose it to as much scrutiny as possible.  It may not be true that with enough bugs... with enough eyes, all bugs are shallow, I mean we saw with OpenSSL and its showstopper bugs even a very large number of eyes if they're passing over the code in a very cursory way, cannot render bugs shallow, but no one has ever argued that with few enough eyeballs, the bugs are shallow. Right? And a necessary but insufficient prerequisite for find out whether a device has a problem is the right to inspect it and publish your findings.  And when we felonize reporting vulnerabilities in devices, those devices become reservoirs of long-lived digital pathogens that have the potential to screw you in every single way, literally, from asshole <points to screen> to appetite.
So we should not be drinking mercury to protect the app-store business model.  And it's not just that DRM bans disclosure.  But the natural workings of DRM make bugs when they appear harder to address.  Because DRM is not software that you or I want. As I said, no one ever woke up and said, "I wish there was a way I could do less with my devices. Who's got a product for that?"  If you had an icon on your desktop when you booted up the manufacturer's default operating system, that said Hal9000.exe and every time you tried to do something the DRM didn't like, it came to the fore and said, "I can't let you do that, Dave," you would drag that icon into the trash. Right?
And so, in order to make DRM work, the files associated with it and the processes that it spawns, have to be obfuscated from the user. And the most common way to do this is what amounts to a rootkit, where you have a... not Ring 0, that has the most authority over the device, but Ring -1, a space that users, even with administrator privileges are not supposed to be able to see or interact with.  And when Ring -1 has a vulnerability and your attacker penetrates that, and attacks you in Ring -1, your attacker is running malware in code that the process manager will not report, or let you end.  When those files are in spaces that your are not allowed to inspect or delete files from, then that is malware that you will never extract from that device and that will be able to operate with impunity.
This is a deadly cocktail, right?  On the one hand we have a legal way to suppress competition that incidentally makes these devices into reservoirs of vulnerabilities, at the same time, devices that are covered by the statute are spreading in every conceivable way and becoming more intimately connected to our device.  Information Security has always mattered, but it matters much more in the Internet of Things.  A failure in Information Security is what turned a million Volkswagens into killing machines, that are anticipated to be responsible for scores of deaths this year, because of the toxic amounts of NOx that they were emitting from their tailpipe and now it looks like they weren't alone, it looks like GM's Opal cars may have been implicated, as well as other cars from other manufacturers.  The obfuscation of what that software was doing is what's responsible for that terrible outcome.
Now last summer, as it does every three years, the US Copyright Office held hearings on this law, section 1201 of the DMCA, the law that makes it a crime to break digital locks to find out what it is doing in the world and whether or not it should grant some limited exemptions from it. And they heard some hair raising stories.  So they heard from people that are involved with automotive security.  You may remember that last July, in a remarkable piece of great timing, some researchers who were planning to present at DefCon demonstrated to Andy Greenburn of Wired that they could, over the Internet seize control GM Jeep Cherokees, take over the steering, the brakes, the ignition, the acceleration, as well as the entertainment system, the wipers, the locks, and so on.  They, as a demo, drove him off the highway at speed.  Now Chrysler had to recall 4 million cars. Now, the researchers came forward with that, risked felony prosecution for disclosing vulnerabilities in car firmware, and what we heard at the US Copyright Office is that it wasn't that Chrysler had the only vulnerable car, it was that Chrysler had the only car whose vulnerabilities someone was willing to talk about in public.  And plenty of security researchers weighed in to say that there were other vulnerabilities that they knew about that their general counsel had told them never to disclose.
iFixIt, I mentioned them before.  They're in San Luis Obispo, they're a company that reverse engineers technology and makes third party manuals that allow service technicians to repair and improve devices, service, repair and improvement account for 3 or 4% of the American GDP, it's all done by small to medium sized enterprises, that are intrinsically local, you don't send your phone to India or China to get it fixed, it's the guy on the corner, the woman on the corner, the little business that fixes it.
He had an amazing filing, because he'd been contacted by a farmer who said, "I have a John Deere tractor, and one day my tractor wouldn't start, because it had a sensor on the wheel that thought I had a flat.  But I didn't have a flat. And I called up John Deere and I said, 'Can you please give me the root password on my tractor so that I can disable that sensor, and you know, make hay while the sun shines.' And John Deere said 'No, sir, you're not allowed to have root on your tractor.  We'll send you a part.'"
And so Kyle and this farmer began to look into it, they filed at the Copyright Office for an exemption, and we began to learn what John Deere does, why they lock up the tractors.  So those wheels have torque sensors on them, and those torque sensors produce centimeter accurate soil surveys.  That data is not copyrightable.  Facts aren't copyrightable.  But it is locked up behind the DRM that locks up the tractor's operating system, which is copyrightable, and is copyrighted and covered under the DMCA, and if you the farmer want to plant your field broadcast your seed in accordance with the soil density, tuned for maximum yield, you can't get that data, except as a bundle with seeds.  And those seeds are sold from one partner that John Deere licenses the data to.  Only one guess as to who that one partner is.  Anyone want to guess?  Monsanto, of course.  But that's just a mustache troll, there's a full-on fingertip coming.  Because John Deere has an insight into crop yields across whole regions.  And they're starting to play the futures market with this data.
Jay Radcliff is a researcher at Rapid 7, and is also a type 1 diabetic. And, as you know, type 1 diabetics have historically drawn assays of their own blood, measured it, taken a bolus of insulin from a vial and stuck themselves with it to maintain their insulin levels. And human beings are really shitty lab techs. Right?  Like asking people to do things perfectly repetitively over and over again, especially when their blood sugar is too high or too low is not a winning proposition.  And that's why today we have insulin pumps connected to continuous glucose monitors that take the human being out of the equation and use robots as lab techs.  Robots are awesome lab techs.  And they, of course, have wireless interfaces because your doctor wants to get the telemetry off them and those wireless interfaces are DRM-locked and the reason that they are DRM-locked is that the companies that make them want to sell your doctor software as a service, they don't want them to buy an app that they only have to pay for once, they want to keep them paying for it every month on a subscription basis.  And as a result, it's against the law to inspect insulin pumps.  Now if you can get an insulin pump to dump its full load of insulin in one go, you will kill the wearer of that insulin pump in their boots, where they stand, almost instantly.  A diabetic coma followed by a quick death.
Jay Radcliff has voluntarily decided to take years off his own life, by not using a continuous glucose monitor and an insulin pump, and instead being a human lab tech because he's inspected his insulin pump and other medical devices, he estimates that 40% of medical device code been independently audited, and he has found stuff in it that he can't describe because his counsel tells him that he would run the risk of the DMCA, but scares the hell out of him to the extent that he won't put one of these devices on his own body.
And of course, we had a team that weighed in about voting machines, they had discovered flaws in voting machines that they couldn't discuss that they believed had materially affected at least one election.
So when you have devices that have festering vulnerabilities in them those devices become more exploitable over the longer period. And there are lots of entities that like to exploit vulnerabilities.  Obviously there's criminals, you've probably heard the horrific stories about "ratters" who are a kind of voyeur who deploy these remote access trojans onto people's computers using drive-by malware attacks, and then they spy on them using their cameras and microphones, capture incidental nudity of them as well as harvesting their social media passwords and then blackmail them into performing live sex acts on their webcams, on threat of disclosure of this information.  There's a young woman in Canada who committed suicide a couple of years ago because she was being targeted by a ratter.  The former Miss Universe, Cass-... or Miss Teen USA, Cassidy Wolf was targeted by a ratter, she went to the FBI, her ratter had at least 140 victims including minor children around the world.  Another round up of ratters found ratters with as many as 400 victims around the world.
So, those people like to exploit vulns.  But there's another entity that likes to exploit vulns, right?  Spy agencies.  Right?  And whether your adversary or threat model is that you're like Nortel, who had all of their trade secrets exfiltrated by Chinese industrial spies and were put out of business or whether your threat model is having the NSA spy on you, both of them are actively exploiting these vulns to attack us. And we don't have a good-guy OS and a bad-guy OS.  If there's a vulnerability that allows our spies to attack their adversaries, it allows their adversary's spies to attack us.
Now, the NSA has a unit called the Tailored Access Operations Unit, they're like the Skymall of the NSA.  they make all the gadgets and exploits, so if you're an NSA agent, you have a target, you know that target has an iPhone, you go to your Tailored Access Operations catalog, and you look up known exploits and weaponized exploits for iPhones, and then you order one, they transfer money from your department's budget to their budget if there's a material cost, like it's on a USB stick or something, and then you can deploy them in the field.  And their argument for not disclosing the vulnerabilities that they're weaponizing to the manufacturers is that they have really good researchers, and the vulnerabilities their researchers discover, no one else will discover.  There's a name for this, called NOBUS -- "No one but us."
And you know, you laugh, and it is laughable, but it's not like a priori that we know this doesn't work, we have proof it doesn't work.  Because two years ago, at a Chaos Communications Congress in Hamburg, Jacob Applebaum presented the Tailored Access Operations catalog which he had released with Laura Poitras and a German investigative magazine and when he was done presenting it, he had his "one more thing" moment.  His "one more things" was that there was an exploit in the Tailored Access Operations manual for iPhones that had been presented by researchers the day before on the same stage, that they had independently discovered, that the NSA had discovered, weaponized, and kept secret and made Americans that they were charged with protecting vulnerable to, and that vulnerability had been detected and an exploit had been made ready by independent parties. And so either it's NOBUS plus that one researcher that one time at CCC, which seems unlikely, or it's NOBUS, plus Chinese spies, griefers, hackers, identity thieves, voyeurs, ratters, and anyone else who wants to exploit you, because your phone is not a supercomputer that you keep in your pocket to throw birds at pigs with, your phone is a supercomputer in your pocket that knows who all your friends are, how to access your bank account, and what your lawyer has told you under confidentiality shield, and also it has ... it's on when you're on the toilet, it's on when your kids are in the bath, it's on when you're in the bedroom, and the only way to know whether that camera is running is when the operating system is being faithful to you.
So when we make our devices into longer-lived reservoirs of vulnerability, we risk all kinds of exploitation.  This is why I went back to EFF.  Because I'm worried about this stuff, I'm worried about how this ties into crime and surveillance.  And the future of this stuff looks pretty grim.
So you may have heard about the sub-prime auto lending industry, there was a big piece in the New York Times about it last year, there are a million sub-prime cars on the road in the United States of America.  These are cars where people don't qualify for a normal car loan, they're given a loan that has conditions on it, one of those conditions is that the car is outfitted with an ignition override that's networked and location-aware.  And the conditions may also restrict where they can drive the cars.  And the New York Times story talked about the security problems of these, and one of the things that happened is that all of the cars ever sold by some dealerships have been immobilized by hackers.  Right, because no language on earth contains the phrase, "As secure as the computers at an auto dealership." Right?  But also, the intentional consequences of these things... they talk about a woman who took her kids for a drive in the countryside and they parked up at the woods, and they walked about for a while, and what she didn't know is that she crossed the county line, and her terms prohibited her crossing the county line, and her car wouldn't start, and she was out of cellular range, and there was no one else around and it was dark, and they had to walk out to the highway and hitchhike home to get their cars back.
So that's where we're already at, in terms of devices that are designed to control their users remotely.  And the risks that are associated with them. But where this lands in the future is really scary.
During the Euromaidan Uprising in Ukraine people who were in the demonstrations in the big square in Kiev went home, and their phones buzzed with an SMS, and the SMS said, "Dear citizen, you are registered as a participant in an illegal demonstration.  Don't do it again."  And the reason that their phones were able to do that is that your phone is designed to resist your modification and to resist your commands to the extent that it will always send a globally unique identifier correctly to the cell tower, basically its MAC address, called IMSI, to the cell tower so you can be correctly billed.  There's an adversarial model between you and your phone, if you could change your IMSI, you could bill your call to third parties, right?  And so your phone is designed, hardened against you changing it and there are these devices that are fake cell towers, they're called cell tower simulators or stingrays, and what they do is they wake up and they beacon, and they say, "Are you a wireless station that's looking for a cell tower?" and all of the phones wake up and say, "Why, yes I am and here's my IMSI."  And then the tower just goes dark, and then if you are the government of Ukraine you can go to the state phone company and get these phone numbers of all of those phones and where those people live and you can send out SMSs to them.
So that's fact 2.  So we have sub-prime cars, we have stingrays and then the third thing...
There's a guy named Hugh Herr who runs the prosthetics lab at MIT.  And he's got much better graphics than me.  <points to screen> I mean, this it it, right?  I do rectal thermometers.  But Hugh Herr will sit there and for 45 minutes, blow your mind with amazing still and moving images of the ways that he and his lab have connected human bodies to computers in ways that profoundly revolutionize people's lives.  Artificial arms, legs, feet, hands, fingers, things that help people see, even neural prostheses, deep magnetic brain stimulation for people with otherwise untreatable depression.  But his best thing, his showstopper, is at the end of the talk he steps out from behind the podium and he clicks to his last slide, and it's a slide of him climbing a mountain, all in Gore-Tex, super ripped, and he's got full radial amputations on both knees, and he's got mountain climbing robot legs. But he's standing there like this, and he says, "Oh, yes, didn't I mention..." and he rolls his pants legs up and he's robot from the knee down.  And he starts running up and down the stage doing mountain goat jumps.  Right?  An incredible demo.  So I put my hand up and I said, "How much did your legs cost?"  And like the price he named you could buy a fully detached home in Bernal Heights, right?  Or Lower East Side.  And then the second question was, "Well, who can afford your legs?"  And he said, "Why everyone.  Because if it's a choice between and 60-year mortgage on your house or a 60-year mortgage on your legs, you'll take the legs any time."   That's the third fact.
What do you get when you combine Euromaidan and Hugh Herr's legs and sub-prime?  You get things like your legs will walk you to the repo-depot when you miss a payment on them, right?  You get things like you come home from your demonstration in the central square, and you have a text that says, "Dear citizen,  you are registered as a participant in an illegal demonstration, and that's why we turned off your Nest thermostat.  Enjoy February in Kiev."  Right?  What it means when our world is made out of computers and our computers are designed to take orders from other people is that everything that is unfair about the power imbalances in our world becomes much harder to address.
So as you may have gathered, I'm a science fiction writer, which is why I talk about the future of Euromaidan and self-driving legs and so on.  And as a science fiction writer people often ask me if I'm optimistic or pessimistic about the future.  And as a science fiction writer I am keenly aware that I have no business making predictions about the future.  Because science fiction writers are Texas marksmen.  They fire a shotgun into a side of a barn and draw a circle around the place where the pellets hit and declare themselves to be world-class marksmen, because although science fiction has had some predictions come true, they're an infinitesimal fraction of all the predictions that science fiction has made.  It would be far more surprising if none of their predictions had come true, than that a small number have come true.  And being optimistic or pessimistic is about making a prediction.  And in some ways, it's an inconsequential view, whether you're optimistic or pessimistic.
Like if I were optimistic, if I thought we could beat all this stuff back, and turn computers into a force for good, the things that excited me and you about computers when we started getting involved with them, the potential for a world in which computers are our servants, they allow us to connect with one another, and to do work together in ways that our ancestors could hardly dream of, you should get up every single morning and do everything you could to make that future come true and make sure this future didn't.
And say you were pessimistic about the future.  And you believed that it was vanishingly unlikely that was ever going to happen.  You should do exactly the same thing.  Right?  Because if there's any chance we can make a difference, then we have to take that chance.  And that's called hope.  Hope is why, when your ship sinks in the middle of the ocean, you tread water.  Not because you're likely to be picked up, but because treading water is a necessary but insufficient precondition for being rescued.  Everyone who was ever rescued kept treading water.
And so I'm here to ask you today to do something to help make computers safe for human co-existence.  We founded this project at EFF, the Apollo 1201 Project, a project to eradicate all DRM laws, everywhere in the world, within a decade.  And it's based on that Larry Lessig framework, Code, Law, Norms, and Markets.  So we are interested in people who are making products or doing research that violate section 1201 of the DMCA, we want to talk to you about how to litigation-harden your work , so if you ever get sued we can use your case to overturn section 1201 of the DMCA.  Thankfully, because section 1201 of the DMCA is now covering every device we have, the likelihood that someone with a good set of facts is going to get sued has gone up.  Used to be the record industry was really careful about who they sued -- Ed Felton, who is now Deputy CIO of the White House, broke the record industry's DRM, [they] declined to sue him, but when 2600 magazine published the code for breaking DVDs, the studios went after them like crazy, because judges don't like telling Princeton mathematicians what they can publish, but the Hacker Quarterly is fair game.  However, we have a target-rich environment now.  Right?  John Deere doesn't care whether section 1201 of the DMCA is intact if they can't use it to play the futures market.  And so when someone is cracking a John Deere tractor, I think it's pretty likely that we'll get a threat from them.
So that's Law.  And the legal theories are manifold about why DRM is against the law, but one of the most important ones ties back to the very first days of EFF and the early days of the crypto-wars.  In the early 90s, you'll remember that it was illegal to break... to make your own crypto, that was stronger than the NSA could break.  It was classed as munitions.  The EFF represented a mathematician named Daniel J. Bernstein at UC Berkeley who had been publishing on Usenet source code for strong crypto.  And the 9th Circuit had held at the appellate division, that source code was a form of expressive speech, protected by the First Amendment and that laws that prohibited publication of source code were unconstitutional.  And so that is one of the ways that we plan on attacking this.  And this mean that particularly if you are engaged in Free and Open Source Software that circumvents, we want to talk to you about what you're doing, we want to talk to you about how to do it so that you have the best chance of winning and making a good case.
We're doing it with Markets.  Because when you think about all of those devices that have digital locks on them, the only reason they're there is to protect a high margin for the manufacturer.  And as Jeff Bezos once admitted in a moment of enormous candor to publishers, "Your margin is my opportunity."  And so once the legal status of section 1201 of the DMCA is uncertain, once it may be that if we win our case, your business that breaks digital locks will also be legal, then it makes sense for you to start a business attacking one of those margins.  Cheaper refills, cheaper parts, service equipment and all the rest of it.  And so we're anticipating a ten year period while our case works its way up to the Supreme Court, and during which time we're hoping that entrepreneurs will seize that market opportunity, not because they care about free and open source software, not because they care about alchemy or science, not because they care about security, but because they want to make themselves wealthy.
And then Norms.  I'm going around talking to people about this, people who understand the more nuanced question.  I want you to talk about that stuff too. Because although most of the people you know are indifferent to these issues, indifferent to privacy, indifferent to questions of free and open source software, indifferent to computer security, we have reached peak indifference. Right?  Every week, every month, from now on there will be disasters involving the Internet of Things, involving information security, involving titanic databases like the Office of Personnel Management.  And every week from now on, because, frankly, we failed to do our jobs during the last 20 years and fix this thing before it was a problem, every week from now on the people that you know and love are going to show up at your door and say, "What the hell do we do?  How did this happen? How did my life end up in this terrible situation? Where I'm getting blackmailed, where my fingerprints are now owned by Chinese spies, where my business is shut down because its trade secrets that have been exfiltrated, where my children are being spied on in their homes."  There was an attack last week in San Francisco where a griefer took control of a baby monitor in the middle of the night and started whispering scary things to a 3-year-old in the middle of the night.  Right?  Your friends will show up at your door every week from now on and ask how we got here.  That's the story I want you to tell them, because we're at peak indifference.
So there's one last thing that I'm going to ask you to do.  So, there are very few of us, even those of us that come to free and open source software events, who can claim to be pure.  You probably, every month, give money to companies whose mission is to destroy the Internet and everything we love about it. Right?  You have a cable account with Comcast, you have a Crystal Pris-- Palace device, a Crystal Prism device from Apple, you are buying a device from a company that bundles their machine with spyware and intermediate certificates, you are doing one of many things... Now, if you can figure out a way to get around those, you want to source your computers from companies that have a more ethical basis, if you want to find an ISP like Monkeybrains in San Francisco, who do everything they can to fight for Net Neutrality, if you can do any of those things, by all mean do, but I think you will still find that at the end of the day, you are not pure. Right?  Every vegetarian eventually meets a Vegan.  Every Vegan eventually meets a pretarian.  So instead of asking you to be pure, or feel guilty about it, I'm going to ask you to tithe, to hedge.  To add up the money you spend every month contributing directly to the destruction of the future we all want to live in and we want to bequeath to our children. And decide what percentage of that you're going to give to organizations that fight for your freedom.  Now I'm obviously partisan, I work for one of them.  You know?  And these folks have been around for a quarter of a century and have done some pretty amazing things in that time, I've never seen a non-profit operate better, but the amazing thing that's happened since I was coming to SoCal LUG in the 90s is that it's not just EFF and the Free Software Foundation (who also deserve your support) anymore. There are dozens of organizations that operate in every conceivable way, there are organizations that help librarians and schools, there are organizations that recycle hardware, like Freecycle in Portland... or Free Geek rather in Portland, there are so many organizations that approach this from so many different angles, Public Knowledge, Fight for the Future, Demand Progress, which Aaron Swarz helped found, how much are you going to give, out of your budget for destroying the future, to save the future.  And then I want to you write that check every month or commit to a regular donation.
The other thing I'm going to ask you to do is if you're involved with a university, if you're a professor or if you're a student, get in touch with me, because we have a new EFF campus network, and we've hired someone full time to work on it, he's an amazing campus organizer, and we want students, especially computer science students, but also student who are working in interdisciplinary fields that touch on this, to get involved with this as well.  There's an EFF booth out on the trade floor here, and I hope you can stop by there and talk to my colleagues there, they can tell you more about all of these things, and thank you very much for your kind attention.
